---
title: "I, Robot?: Part 2"
date: 2022-02-04
---

This is a continuation of my [previous blog post](https://ninjajoe9.github.io/i-robot/) that ran long so I elected to finish it later. If you don't feel like going back and reading that one first, I am examining how Isaac Asimiov's "I, Robot" written in the 1940's has some amazingly accurate predictions about the state of robots today, at least from an engineering standpoint. I'll dive right back in with my comments on the next chapter.

and again **SPOILER WARNING** if you intend to read the book.

### Algorithmic Cruelty

This concept is less of a robotics notion than it is a generally software notion, that if you have an ill defined system, the system isn't responsible for the unintended results you get when you feed it unintended data. "Liar!" focus on robot model RD-34, or 'Herbie', that has the unique ability to read human minds. While we have nothing today that can directly read all human minds, the field of neuro-interfaces is rapidly evolving and a very interesting field of study. It is also not what I intend to focus on for this section....

The drama of this chapter arises from the interplay of Herbie's mind reading the first law of robotics, preventing robots from harming humans. In this case the robot interacts with humans, reads their thoughts and desires, and in an effort to not cause short term emotional harm, lies to them about the outcome of their desires even though it know what they said to be false. Since we don't actually have mind reading robots yet I won't comment on the ability of a robot to judge emotional harm, but many questions about ethics and the notion of 'harm' that are addressed in this chapter are relevant to roboticists today. The ill defined notion of 'harm' as interpreted by the robot gives rise to the concept of algorithmic cruelty mentioned above. The idea that the three laws of robotics, despite being well intended, and seemingly well thought out, are far from perfect and do not capture a large number of edge cases. Just like much software, you don't need the added complexity of mind reading to see disastrous results.

### Military Robots

"Little Lost Robot" tells the story of a set of secret military robots that are intentionally designed with reduced 1st law instructions to enable them to work with humans in hazardous, mildly radioactive, asteroid mining environment, where without the limitations, the robots immediately go into rescue mode and remove the humans from the location since their mere presence is causing them harm. Chaos (and an interesting story) ensue when the reduced compliance to the first law allows one of these modified robots to "get lost" in a sea of identical models who fully conform to the three laws.

Asimov's three laws are artificially placed on the robots to drive story elements in his work. In the real world no such necessary conditions exist to restrict the working of robots and they are entirely dependent on the nature of the systems created to operate them. While robot designers overwhelmingly don't make robots with any intent to harm humans, we know this isn't universally true. Depending on the definition of 'robot', military drones could be considered in this category and have been heavily employed in the prosecution of the Global War on Terror. On the other hand, self driving cars and other autonomous vehicles are designed with no intent whatsoever to harm their passengers, and have resulted in at least a few deaths of humans when things go wrong. I'm not trying to make the case that we should or should not find some version of three laws control, I just wish to address the notion that automating any system in the physical world results in powerful effects that comes with risks; enough so that it even made for a compelling story 75 years ago when we just considered the idea of a rogue robot with the ability to harm humans...

### Creativity in Artificial Intelligence

Machine learning and Artificial Intelligence are progressing rapidly and have even extended into creative spaces the design visual art, literature and music indistinguishable from humans [^1]. This even extends to engineering and design where genetic algorithms are created that can design or optimize structures that are far removed from what humans have conceived of previously, but achieve much better results. While the movie _I, Robot_ departs from the book in many ways, I love the interaction between Will Smith's character Detective Spooner asks the robot Sonny (voiced by the wonderful Alan Tudyk) "Can a robot write a symphony? Can a robot turn a canvas into a beautiful masterpiece?" to which Sonny responds "Can you?". I think it's a fantastic scene that illustrates a wonderful point about what art is.  "Escape" depicts a robot called "Brain" that is contracted from US Robotics from another company to solve a problem their computer was unable to fathom. At the end of the computation, the Brain is able to develop the Hyperatomic Drive allowing travel through interstellar space, an invention far beyond the capability of the humans in the novel to design. In our world we see AI creating and solving mathematical proofs; GitHub copilot is a new service that automatically writes code for the user, again, with mixed results, but rapidly improving. I can only imagine what leaps in science and technology will result from AI applications in the near future.

### The Robotic Singularity

The singularity in the context of robotics is the notion that at some point robots will not only become indistinguishable from human beings, but also reach a point that they surpass human ability in every aspect. Computers certainly surpass humans in areas such as computational speed, quantity of information storage and recall. Robots surpass humans in strength, precision and speed, as well as possess capabilities like flight or underwater persistence. Where robots and computers do not surpass humans involve areas that are more ephemeral and less quantifiable such as creativity, empathetic response and perhaps questions as metaphysical as "possession of a soul" [^2]. "Evidence" describes a being known as Stephen Byerley. I say 'being' because the entire chapter revolves around whether or not Mr. Byerley is in fact a Human or a Robot. The story involves a political rival approaching US Robotics asking Dr. Calvin to prove his suspicions that Mr. Byerly is a robot. Since US Robotics is the only company able to produce positronic brains they deny the possibility despite the insistence of the rival. The severity of the accusation is increased by the fact that Mr. Byerly is also a candidate for Mayor. Ultimately the matter is 'solved' at the end of the story when he punches a human, thus 'violating' the first law of robotics proving he is human. However in the last few paragraphs of the chapter Dr. Calvin reveals to the journalist/narrator that this wouldn't have violated the first law if the man who was punched was also a robot... This seems to confirm her suspicions that Mr. Byerly is indeed a robot and won the mayoral election anyway. The idea that one day robots may be functionally indistinguishable from humans brings up many ethical questions of autonomy and identity, that thankfully we are not required to answer today, but may well need to contend with in the future.  

### I, For One, Welcome Our Robot Overlords

The final chapter of the book, Mr. Byerly is serving as the world coordinator for the planet Earth as humanity has begun its expansion to the stars with the new invention of the hyperatomic drive. Most of the world is run by four regional coordinators assisted by four prime machines (AI's), one for each of the main Regions. They handle all the low level logistics and planning needed to keep the human population alive and thriving. Things begin to go wrong, and small failures in some industries and labor pools around the world, so the question as to whether or not the task of managing all the data in an incredibly high-degree configuration space of variables is too great even for the four machines working in concert. Ultimately it is discovered that in an attempt to minimize harm and maximize societal happiness the machines are intentionally allowing some industries to fail so that other more important industries succeed. The question as to whether this is good or not is left unanswered, but it is certain it is not the human coordinators who are in control.

The implication of a robot controlled society is not new to speculative/science fiction. Skynet, The Matrix and other dystopian futures paint a picture where robots control every aspect of our lives and fundamentally undermine any original purpose of existing as humans in the first place. I don't think we are resigned to this fate. I do think, as many futurists to including Yuval Harari and Nick Bostrom speculate, we will merge as a species with technology, not specifically in a cybernetic sense (although not _NOT_ saying that either) but in that we will begin to work more and more in concert with the technologies that develop around us and become something entirely different socially. This idea isn't particularly new but certainly not one examined by Asimov in this book as he tries to draw distinct lines between man and machine, while at the same time trying to find where they cross over. He does very much maintain they are similar, maybe even functionally identical in every way, but distinct.

I don't pretend to know or even have a very good idea of what technology of the future will bring about, I just hope to be one of the people driving it to a vision of something positive and something we build intentionally instead of a vision we fall into out of our own neglect. But if at the end of the day we can build society with less suffering, more progress and more understanding, while still retaining purpose, and technology is the path that gets us there? I, for one, welcome our robot overlords...




[^1]: ...with mixed results... see [Harry Potter except it's written by an AI](https://youtu.be/6rEkKWXCcR4)
[^2]: More on the concept of a soul in blog posts in the near future
